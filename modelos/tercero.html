<!DOCTYPE html>
<html lang="es">
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta name="author" content="Universidad Sergio Arboleda">
	<meta name="description" content="Proyecto final | Introducción a IA+CC | Universidad Sergio Arboleda">
	<link rel="stylesheet" type="text/css" href="../stylesheet.css">
	<title>Proyecto Final</title>
	<link  rel="icon" type="favicon" href="img/favicon.ico"/>
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-giJF6kkoqNQ00vy+HMDP7azOuL0xtbfIcaT9wjKHr8RbDVddVHyTfAAsrekwKmP1" crossorigin="anonymous">
</head>
<body background="img/bg.jpg">
	<div class="container">
		<header class="row mb-3"> <!-- ENCABEZADO -->
			<div class="col">
				<h1 class="text-center">MODELO DE POSTURAS</h1>
			</div>
		</header>
		<div class="row mb-3 menu justify-content-center">
			<div class="col">
				<ul class="nav nav-pills nav-fill justify-content-center">
					<li class="nav-item"><a href="../index.html" class="nav-link">INICIO</a></li>
					<li class="nav-item"><a href="primero.html" class="nav-link">IMAGEN</a></li>
					<li class="nav-item"><a href="segundo.html" class="nav-link">AUDIO</a></li>
					<li class="nav-item"><a href="#" class="nav-link active" aria-current="page">POSTURAS</a></li>
				</ul>
			</div>
		</div>
		<div class="row contenedor justify-content-center">
			<hr>
			<main class="row col-lg-4 col-11 m-webcam"> 
				<div class="justify-content-center webcam">
					<div class="col">
						<h3 class="text-center tit-pd">POSTURAS</h3>
					</div>
					<div id="label-container" class="row text-center"></div>
						<center>
							<div class="row col-lg-12 col-8">
								<canvas id="canvas"></canvas>
							</div>
						</center>
					<div class="row boton">
						<button type="button" class="btn-primary" onclick="init()">INICIAR MODELO</button>
					</div>
				</div>
			</main>
			<main class="row col-lg-8 col-11">
				<div class="descripcion">
					<h3 class="text-center tit-pd">DESCRIPCIÓN</h3>
					<p class="p-des">
						En el modelo de posturas se tuvo que crear 3 clases: brazo derecho, brazo izquierdo
						y ningún brazo. El objetivo era que el modelo pudiera determinar qué brazo se estaba
						levantando o cuando se estaba levantando. Para eso se empezó a entrenar el modelo
						varias veces, se le agregaron distintas formas de levantar los brazos para que el
						modelo pudiera determinar las diferentes opciones de levantar el brazo. Para que
						funcionara de la mejor manera se tuvo que realizar varias muestras. Y finalmente se
						obtuvo el modelo deseado el cual distingue correctamente que brazo se encuentra alzado.
					</p>
				</div>
			</main>
			<hr>
		</div>
		<div class="row">
			<footer class="col mt-3 d-flex justify-content-between"> <!-- PIE DE PÁGINA -->
				<div>
					<h6>PROYECTO FINAL | 2022-01</h6>
				</div>
				<div>
					<h6>INTRODUCCIÓN A IA+CC</h6>
				</div>
			</footer>
		</div>
	</div>
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta1/dist/js/bootstrap.bundle.min.js"></script>
	<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
	<script src="https://cdn.jsdelivr.net/npm/@teachablemachine/pose@0.8/dist/teachablemachine-pose.min.js"></script>
	<script type="text/javascript">
		// More API functions here:
		// https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/pose
	
		// the link to your model provided by Teachable Machine export panel
		const URL = "https://teachablemachine.withgoogle.com/models/b06ifZiQMK/";
		let model, webcam, ctx, labelContainer, maxPredictions;
	
		async function init() {
			const modelURL = URL + "model.json";
			const metadataURL = URL + "metadata.json";
	
			// load the model and metadata
			// Refer to tmImage.loadFromFiles() in the API to support files from a file picker
			// Note: the pose library adds a tmPose object to your window (window.tmPose)
			model = await tmPose.load(modelURL, metadataURL);
			maxPredictions = model.getTotalClasses();
	
			// Convenience function to setup a webcam
			const size = 200;
			const flip = true; // whether to flip the webcam
			webcam = new tmPose.Webcam(size, size, flip); // width, height, flip
			await webcam.setup(); // request access to the webcam
			await webcam.play();
			window.requestAnimationFrame(loop);
	
			// append/get elements to the DOM
			const canvas = document.getElementById("canvas");
			canvas.width = size; canvas.height = size;
			ctx = canvas.getContext("2d");
			labelContainer = document.getElementById("label-container");
			for (let i = 0; i < maxPredictions; i++) { // and class labels
				labelContainer.appendChild(document.createElement("div"));
			}
		}
	
		async function loop(timestamp) {
			webcam.update(); // update the webcam frame
			await predict();
			window.requestAnimationFrame(loop);
		}
	
		async function predict() {
			// Prediction #1: run input through posenet
			// estimatePose can take in an image, video or canvas html element
			const { pose, posenetOutput } = await model.estimatePose(webcam.canvas);
			// Prediction 2: run input through teachable machine classification model
			const prediction = await model.predict(posenetOutput);
	
			for (let i = 0; i < maxPredictions; i++) {
				const classPrediction =
					prediction[i].className + ": " + prediction[i].probability.toFixed(2);
				labelContainer.childNodes[i].innerHTML = classPrediction;
			}
	
			// finally draw the poses
			drawPose(pose);
		}
	
		function drawPose(pose) {
			if (webcam.canvas) {
				ctx.drawImage(webcam.canvas, 0, 0);
				// draw the keypoints and skeleton
				if (pose) {
					const minPartConfidence = 0.5;
					tmPose.drawKeypoints(pose.keypoints, minPartConfidence, ctx);
					tmPose.drawSkeleton(pose.keypoints, minPartConfidence, ctx);
				}
			}
		}
	</script>
</body>
</html>